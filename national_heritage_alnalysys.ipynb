{
 "cells": [
  {
   "cell_type": "code",
   "id": "c88a8ac985d1362b",
   "metadata": {},
   "source": "# !pip install -e /Users/esummer/workspace/python/my-python-utils-main",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!pip install slugify\n",
    "\n",
    "!pip install pandas\n",
    "!pip install selenium\n",
    "!pip install openpyxl\n",
    "\n",
    "!pip install requests pandas xmltodict\n",
    "!pip install etree\n",
    "!pip install lxml\n",
    "\n",
    "!pip install --upgrade pip\n"
   ],
   "id": "aade1627edf32399",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e780d05ae8b8ece5",
   "metadata": {},
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from slugify import slugify\n",
    "import csv\n",
    "\n",
    "import logging\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.firefox_profile import FirefoxProfile\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "import re"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## êµ­ê°€ìœ ì‚°ì²­ Open API",
   "id": "de44628f45964406"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "df = pd.DataFrame()\n",
    "error_urls = []\n",
    "for i in range(1, int(17737 / 50) +1 ):\n",
    "    url = f'http://www.khs.go.kr/cha/SearchKindOpenapiList.do?pageUnit=50&pageIndex={i}'\n",
    "\n",
    "    try:\n",
    "        # 2. ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (requests ì´ìš©)\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # 200 OKê°€ ì•„ë‹ˆë©´ ì—ëŸ¬ ë°œìƒ\n",
    "\n",
    "        # 3. XML ë°ì´í„°ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜\n",
    "        # êµ­ê°€ìœ ì‚°ì²­ API ê²°ê³¼ì—ì„œ ê° í•­ëª©ì€ <item> íƒœê·¸ ì•ˆì— ë“¤ì–´ìˆìœ¼ë¯€ë¡œ xpathë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "        df_a = pd.read_xml(response.content, xpath=\".//item\")\n",
    "        df = pd.concat([df, df_a], ignore_index=True)\n",
    "\n",
    "        df_a.to_excel(f'{i:04d}_SearchKindOpenapiList.xlsx')\n",
    "        # 4. ê²°ê³¼ í™•ì¸\n",
    "        print(f\"ë°ì´í„° í¬ê¸°: {df.shape}\")\n",
    "        # print(df.head())\n",
    "        time.sleep(1)\n",
    "    except Exception as e:\n",
    "        print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        error_urls.append(url)\n",
    "    pass\n"
   ],
   "id": "86845ba486b56e9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.to_excel(\"êµ­ê°€ìœ ì‚°.xlsx\", index=False)",
   "id": "2d67fd1885ac91b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## êµ­ê°€ìœ ì‚° ê²€ìƒ‰ ìƒì„¸",
   "id": "9872a26e5f7e0f4e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_base = pd.read_excel(\"êµ­ê°€ìœ ì‚°.xlsx\")",
   "id": "9a85913a03d9a6a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import ET\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# í•œêµ­ íƒ€ì„ì¡´ ì„¤ì •\n",
    "korea_timezone = pytz.timezone('Asia/Seoul')\n",
    "\n",
    "step_count = 3000\n",
    "step = 1 +1+1+1+1+1\n",
    "\n",
    "start = ((step -1) * step_count)\n",
    "\n",
    "print(start, start + step_count)\n",
    "for index, row in df_base.iterrows() :\n",
    "\n",
    "    if index < start + step_count and index >= start:\n",
    "        ccbaKdcd = row['ccbaKdcd']\n",
    "        ccbaAsno = row['ccbaAsno']\n",
    "        ccbaCtcd = row['ccbaCtcd']\n",
    "        file_name = row['ccbaMnm1']\n",
    "\n",
    "        ccbaAsno = f'0000000{ccbaAsno}'\n",
    "        ccbaAsno = ccbaAsno[-13:]\n",
    "\n",
    "        surl = f\"https://www.khs.go.kr/cha/SearchKindOpenapiDt.do?ccbaKdcd={ccbaKdcd}&ccbaAsno={ccbaAsno}&ccbaCtcd={ccbaCtcd}\"\n",
    "\n",
    "        if (index % 50 == 0):\n",
    "            # í˜„ì¬ ì‹œê°„ ê°€ì ¸ì˜¤ê¸°\n",
    "            now_korea = datetime.now(korea_timezone)\n",
    "            # ì¶œë ¥ í˜•ì‹ ì§€ì •\n",
    "            formatted_time = now_korea.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(\"\", formatted_time, index+1, surl)\n",
    "\n",
    "        try:\n",
    "            file_path = Path(f'./detail/{index:05d}_ìƒì„¸_{file_name}.xlsx')\n",
    "\n",
    "            # 1. íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬ ì¡´ì¬ ì—¬ë¶€ ì „ì²´\n",
    "            if file_path.exists():\n",
    "                continue\n",
    "\n",
    "            print(\"*\", end=\"\")\n",
    "\n",
    "            # 2. ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (requests ì´ìš©)\n",
    "            response = requests.get(surl)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            df_a = pd.read_xml(response.content, xpath=\".//item\")\n",
    "            df = pd.concat([df, df_a], ignore_index=True)\n",
    "\n",
    "            df_a.to_excel(file_path)\n",
    "\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            print(index, surl)"
   ],
   "id": "539051ee827e58cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ìƒì„¸ì •ë³´ ë¨¸ì§€ ",
   "id": "335e5d2e83b02eee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "external_directory = '/Volumes/SSD2014/datafile/detail'\n",
    "image_home = '/Volumes/SSD2014/datafile/image'\n",
    "\n",
    "count = 0\n",
    "for path in Path(f'{external_directory}').rglob('*.xlsx'):\n",
    "    count += 1\n",
    "    if count % 500 == 0:\n",
    "        # print(f\"ì°¾ì€ íŒŒì¼: {path}\")\n",
    "        pass \n",
    "    \n",
    "\n",
    "detail_not_found = []\n",
    "df = pd.read_excel(\"ì´ë¯¸ì§€_êµ­ê°€ìœ ì‚°___.xlsx\")\n",
    "for index, row in df.iterrows():\n",
    "    detail_file_path = Path(f'{external_directory}/{index:05d}_á„‰á…¡á†¼á„‰á…¦_{row[\"ccbaMnm1\"]}.xlsx')\n",
    "    if not detail_file_path.exists():\n",
    "        detail_not_found.append(detail_file_path.absolute())\n",
    "    else:\n",
    "        df_detail = pd.read_excel(detail_file_path.absolute())\n",
    "        content = df_detail.iloc[0]['content']        \n",
    "        df.at[index, 'detail_info'] = content\n",
    "        \n",
    "        if index % 500 == 0:\n",
    "            print(f\"ì°¾ì€ íŒŒì¼: {detail_file_path.is_file()} {detail_file_path.absolute()}\")\n"
   ],
   "id": "70fc370ad1513ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.to_excel(\"ì´ë¯¸ì§€_êµ­ê°€ìœ ì‚°_ì½˜í…ì¸ .xlsx\", index=False)\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame(detail_not_found)\n",
    "df2.to_excel(f'./output/detail_not_found.xlsx')"
   ],
   "id": "2165c19a9f6cbea5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ì´ë¯¸ì§€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
   "id": "f3774d31dd42e38f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install Pillow",
   "id": "d0f1981718d8937b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "def compress_image(file_path, target_size_mb=5):\n",
    "    target_size_bytes = target_size_mb * 1024 * 1024\n",
    "\n",
    "    # í˜„ì¬ íŒŒì¼ í¬ê¸° í™•ì¸\n",
    "    file_size = os.path.getsize(file_path)\n",
    "\n",
    "    if file_size <= target_size_bytes:\n",
    "        print(f\"ì´ë¯¸ {file_path.name}ì˜ ìš©ëŸ‰ì´ {target_size_mb}MB ì´í•˜ì…ë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    print(f\"ì••ì¶• ì‹œì‘: {file_path.name} ({file_size / (1024*1024):.2f}MB)\")\n",
    "\n",
    "    # ì´ë¯¸ì§€ ì—´ê¸°\n",
    "    img = Image.open(file_path)\n",
    "    img_format = img.format if img.format else \"JPEG\"\n",
    "\n",
    "    # 1ë‹¨ê³„: í’ˆì§ˆ(Quality)ì„ ë‚®ì¶°ì„œ ì €ì¥ ì‹œë„\n",
    "    quality = 90\n",
    "    while file_size > target_size_bytes and quality > 10:\n",
    "        img.save(file_path, format=img_format, quality=quality, optimize=True)\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        quality -= 10  # í’ˆì§ˆì„ 10ì”© ë‚®ì¶¤\n",
    "\n",
    "    # 2ë‹¨ê³„: í’ˆì§ˆì„ ë‚®ì¶°ë„ ì—¬ì „íˆ í¬ë‹¤ë©´ í•´ìƒë„(Resize) ì¶•ì†Œ\n",
    "    while file_size > target_size_bytes:\n",
    "        width, height = img.size\n",
    "        # ê°€ë¡œ ì„¸ë¡œë¥¼ 10%ì”© ì¤„ì„\n",
    "        img = img.resize((int(width * 0.9), int(height * 0.9)), Image.Resampling.LANCZOS)\n",
    "        img.save(file_path, format=img_format, quality=quality, optimize=True)\n",
    "        file_size = os.path.getsize(file_path)\n",
    "\n",
    "    print(f\"ì••ì¶• ì™„ë£Œ: {file_path.name} ({file_size / (1024*1024):.2f}MB)\")"
   ],
   "id": "2a080d4ecd5a1c83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "\n",
    "df = pd.read_excel(\"ì´ë¯¸ì§€_êµ­ê°€ìœ ì‚°___.xlsx\")\n",
    "\n",
    "step_count = 5000\n",
    "step = 4\n",
    "\n",
    "start = ((step -1) * step_count)\n",
    "\n",
    "print(start, start + step_count)\n",
    "\n",
    "datafile_base = '/Volumes/SSD2014/datafile'\n",
    "\n",
    "df['read_file'] = df['read_file'].replace('nan', None)\n",
    "# df_filtered = df[df['read_file'].str.len() > 3]\n",
    "\n",
    "error_urls = []\n",
    "df_filtered = df[df['read_file'].notna()]\n",
    "for index, row in df_filtered.iterrows():\n",
    "\n",
    "    if index < start + step_count and index >= start:        \n",
    "        file_name = f\"{datafile_base}/output/{row['read_file']}\"\n",
    "    \n",
    "        image_source_path = Path(file_name)\n",
    "        \n",
    "        print('ğŸŸ¢', index, end=' ')\n",
    "        if index % 100 == 0:\n",
    "            print(index, image_source_path.exists(), image_source_path.absolute()) \n",
    "        if image_source_path.exists():\n",
    "            df_image = pd.read_excel(image_source_path.absolute())\n",
    "            image_type = row[\"images_type\"]\n",
    "            sub_path = row[\"ccbaMnm1\"]\n",
    "            # print(sub_path)\n",
    "            image_home_path = Path(f'{datafile_base}/image/{image_type}/{sub_path}')\n",
    "            image_home_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            df_detail = pd.read_excel(file_name)\n",
    "            \n",
    "            txt_file = f\"{datafile_base}/text/{image_type}/{row['read_file'].split('.')[0]}({len(df_detail)}).txt\"\n",
    "            \n",
    "            if(not Path(txt_file).exists()):\n",
    "                with open(txt_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(f\"#ë“±ë¡ëª…:\")\n",
    "                    f.write(row['ccbaMnm1']+\"\\n\")\n",
    "\n",
    "                    # f.write(f\"#detail_info\\n\")\n",
    "                    # f.write(row['detail_info']+\"\\n\")                        \n",
    "\n",
    "                    f.write(f\"#longitude:\")\n",
    "                    f.write(f\"{row['longitude']}\"+\"\\n\")\n",
    "\n",
    "                    f.write(f\"#latitude:\")\n",
    "                    f.write(f\"{row['latitude']}\"+\"\\n\")\n",
    "\n",
    "                    f.write(f\"#image_files\\n\")\n",
    "                    \n",
    "                    for ii, iirow in df_detail.iterrows():\n",
    "    \n",
    "                        image_name = iirow['ccimDesc'].replace(\":\",\"^\").replace(\"/\",\"&\").replace(\" \",\"_\").replace(\"\\t\",\"_\")\n",
    "                        sn = iirow['sn']\n",
    "                        ext = iirow['imageUrl'].split('.')[-1]\n",
    "        \n",
    "                        image_download_path = f'{image_home_path}/{image_name}_{sn:03d}.{ext}'\n",
    "                        \n",
    "                        f.write(image_download_path)\n",
    "                        f.write(\"\\n\")\n",
    "\n",
    "                \n",
    "            print(f'({len(df_detail)}) {sub_path}', end=\" \")\n",
    "            for ii, iirow in df_detail.iterrows():\n",
    "                # file_name.replace(\":\",\"^\").replace(\"/\",\"&\").replace(\" \",\"_\").replace(\"\\t\",\"_\")\n",
    "                \n",
    "                image_name = iirow['ccimDesc'].replace(\":\",\"^\").replace(\"/\",\"&\").replace(\" \",\"_\").replace(\"\\t\",\"_\")\n",
    "                sn = iirow['sn']\n",
    "                ext = iirow['imageUrl'].split('.')[-1]\n",
    "                \n",
    "                image_download_path = f'{image_home_path}/{image_name}_{sn:03d}.{ext}'\n",
    "    \n",
    "                try:\n",
    "                    if not Path(image_download_path).exists() or len(Path(image_download_path).read_bytes()) == 0:\n",
    "\n",
    "                        response = requests.get(iirow['imageUrl'], stream=True)\n",
    "                        response.raise_for_status()  # 200 OKê°€ ì•„ë‹ˆë©´ ì—ëŸ¬ ë°œìƒ\n",
    "                        with open(image_download_path, 'wb') as f:\n",
    "                            for chunk in response.iter_content(1024):\n",
    "                                f.write(chunk)\n",
    "                        print('ğŸ‡°ğŸ‡·', end=\"\")\n",
    "                except Exception as e:                    \n",
    "                    error_urls.append(iirow['imageUrl'])                    \n",
    "                    print(f\"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}\")                \n",
    "                \n",
    "                if ii >= 7+3:\n",
    "                    break\n",
    "            \n",
    "        print(f' ğŸŸ¤')\n",
    "\n",
    "df_error = pd.DataFrame(error_urls, columns=['error_url'])\n",
    "df_error.to_excel('error.xlsx')\n",
    "\n",
    "end = datetime.now()  # ì¢…ë£Œ ì‹œì \n",
    "\n",
    "diff = end - start_time\n",
    "seconds = diff.total_seconds()\n",
    "\n",
    "hours = int(seconds // 3600)\n",
    "minutes = int((seconds % 3600) // 60)\n",
    "seconds = int(seconds % 60)\n",
    "\n",
    "print(f\"ì‘ì—… ì†Œìš” ì‹œê°„: {hours}ì‹œê°„ {minutes}ë¶„ {seconds}ì´ˆ\")"
   ],
   "id": "b5eab166955a30bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‡°ğŸ‡·"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "\n",
   "id": "8443ee003c5a6b90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## êµ­ê°€ìœ ì‚° ëª©ë¡ì—ì„œ ì´ë¯¸ì§€íŒŒì¼ ì¡°íšŒ",
   "id": "46050b6625c81c58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "external_directory = '/Volumes/SSD2014/datafile'\n",
    "\n",
    "df = pd.read_excel(\"êµ­ê°€ìœ ì‚°.xlsx\")\n",
    "# df.head()"
   ],
   "id": "b1b04f0e675045b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ì´ë¯¸ì§€ ê²½ë¡œ API",
   "id": "577a41f1f168df65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import ET\n",
    "from pathlib import Path\n",
    "step = 1000\n",
    "step = 10\n",
    "\n",
    "start = 1000 +500 +500 +500 +500 +500 +1000 +1000 +step+step\n",
    "start = 11500+step\n",
    "start = 6500\n",
    "start = 17500\n",
    "start = 0\n",
    "\n",
    "for index, row in df.iterrows() :\n",
    "\n",
    "    if index < start + step and index >= start:\n",
    "        ccbaKdcd = row['ccbaKdcd']\n",
    "        ccbaAsno = row['ccbaAsno']\n",
    "        ccbaCtcd = row['ccbaCtcd']\n",
    "        file_name = row['ccbaMnm1']\n",
    "\n",
    "        ccbaAsno = f'0000000{ccbaAsno}'\n",
    "        ccbaAsno = ccbaAsno[-13:]\n",
    "\n",
    "        surl = f'https://www.khs.go.kr/cha/SearchImageOpenapi.do?ccbaKdcd={ccbaKdcd}&ccbaAsno={ccbaAsno}&ccbaCtcd={ccbaCtcd}'\n",
    "        if(index % 20 == 0):\n",
    "            # print(index, surl)\n",
    "            pass\n",
    "        try:\n",
    "            file_path = Path(f'./output/{index:05d}_image_{file_name}.xlsx')\n",
    "\n",
    "            # 1. íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬ ì¡´ì¬ ì—¬ë¶€ ì „ì²´\n",
    "            if file_path.exists():\n",
    "                continue\n",
    "\n",
    "\n",
    "            # 2. ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (requests ì´ìš©)\n",
    "            response = requests.get(surl)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            items = response.content\n",
    "\n",
    "            root = ET.fromstring(response.content)\n",
    "\n",
    "            result_list = []\n",
    "            current_item = {}\n",
    "\n",
    "            # 2. ëª¨ë“  í•˜ìœ„ ìš”ì†Œë¥¼ ìˆœíšŒí•˜ë©° snì„ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”\n",
    "            for child in root:\n",
    "\n",
    "                # print(child.tag, child.text)\n",
    "\n",
    "                if child.tag == 'item':\n",
    "                    for child2 in child:\n",
    "                        # print(child2.tag, child2.text)\n",
    "                        # ìƒˆë¡œìš´ <sn>ì„ ë§Œë‚˜ë©´ ì´ì „ê¹Œì§€ ìŒ“ì¸ current_itemì„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "                        if child2.tag == 'sn' and current_item:\n",
    "                            result_list.append(current_item)\n",
    "                            current_item = {}  # ì´ˆê¸°í™”\n",
    "\n",
    "                        # ë°ì´í„° ì¶”ê°€ (íƒœê·¸ ì´ë¦„ì„ í‚¤ë¡œ, í…ìŠ¤íŠ¸ë¥¼ ê°’ìœ¼ë¡œ)\n",
    "                        current_item[child2.tag] = child2.text\n",
    "\n",
    "                    # 3. ë§ˆì§€ë§‰ì— ë‚¨ì€ í•­ëª© ì¶”ê°€\n",
    "                    if current_item:\n",
    "                        result_list.append(current_item)\n",
    "\n",
    "            if(index % 20 == 0):\n",
    "                print(result_list)\n",
    "\n",
    "            df2 = pd.DataFrame(result_list)\n",
    "            df2.to_excel(f'./output/{index:05d}_image_{file_name}.xlsx')\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            print(index, surl)\n"
   ],
   "id": "78301cd31af5be97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = pd.read_excel('ì´ë¯¸ì§€_êµ­ê°€ìœ ì‚°___.xlsx')",
   "id": "5429dd313c79199d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "words = \"ì„íƒ‘,ì…ìƒ,ì¢Œìƒ,ì¹ ì„±ë„,ì„ë“±,ê·¹ë½ì „,ê·¹ë½ë³´ì „,ì „íƒ‘,ë¬´ëŸ‰ìˆ˜ì „,ë¶ˆêµ­ì‚¬,í•´ì¸ì‚¬,ì†¡ê´‘ì‚¬,í†µë„ì‚¬,ë°±ë‹´ì‚¬,ë™í™”ì‚¬,ë²½í™”,ëŒ€ì›…ì „,ìŠ¹íƒ‘,ë²•ì£¼ì‚¬,ì—¬ë˜,êµ­ì‚¬íƒ‘,ì‚¬íƒ‘,ê´˜ë¶ˆíƒ±,íƒ±í™”,ë™ì¢…,ë°˜ê°€ìƒ,ë¯¸ë¥µë¶ˆ,ë³´ì‚´,ë‚˜í•œìƒ,ê´˜ë¶ˆ\".split(\",\")\n",
    "words = \"êµíšŒ,ì„±ë‹¹,ì˜ˆë°°\".split(\",\")\n",
    "words = \"ë‚˜ë¬´,ìˆ˜ë¦¼\".split(\",\")\n",
    "words = \"ë°•ë¬¼ê´€\".split(\",\")\n",
    "\n",
    "files = []\n",
    "\n",
    "for index, row in df.iterrows() :\n",
    "    ccbaKdcd = row['ccbaKdcd']\n",
    "    ccbaAsno = row['ccbaAsno']\n",
    "    ccbaCtcd = row['ccbaCtcd']\n",
    "\n",
    "    # df.at[index, 'images'] = 0\n",
    "\n",
    "    file_name = row['ccbaMnm1']\n",
    "    if any(word in file_name for word in words):\n",
    "        readfile = f'{index:05d}_image_{file_name}.xlsx'\n",
    "\n",
    "        directory = file_name.replace(\":\",\"^\").replace(\"/\",\"&\").replace(\" \",\"_\").replace(\"\\t\",\"_\")\n",
    "\n",
    "        images = []\n",
    "\n",
    "        try:\n",
    "            df2 = pd.read_excel(f\"./output/{readfile}\")\n",
    "            for ii, rr in df2.iterrows():\n",
    "                # if ii > 9:\n",
    "                #     break\n",
    "                data = {}\n",
    "                data['url'] = rr['imageUrl']\n",
    "\n",
    "                if(data['url'].find('no_image') > -1):\n",
    "                    continue\n",
    "\n",
    "                ext = data['url'].split('.')[-1]\n",
    "                sn = rr['sn']\n",
    "                name = f\"{rr['ccimDesc']}\".replace(\":\",\"^\").replace(\"/\",\"&\").replace(\" \",\"_\").replace(\"\\t\",\"_\")\n",
    "                data['name'] = f'{directory}@@{name}##{sn}.{ext}'\n",
    "                images.append(data)\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "        finally:\n",
    "            if len(images) > 0:\n",
    "                df.at[index, 'read_file'] = readfile\n",
    "                df.at[index, 'images'] = len(images)\n",
    "                df.at[index, f'images_type'] = \"|\".join(words[:3])\n",
    "                files.append(readfile)\n",
    "\n",
    "    # if(index > 10000):\n",
    "    #     break\n",
    "\n",
    "df3 = pd.DataFrame(files, columns=['Name'])\n",
    "df3.to_excel(f'{\"\".join(words)}___.xlsx')\n",
    "df.to_excel(f'ì´ë¯¸ì§€_êµ­ê°€ìœ ì‚°___.xlsx')\n",
    "print(\"íŒŒì¼ê°¯ìˆ˜\",len(files),\"\\n\", \"Latest\\n\",\"\\n\".join(files[-10:]))"
   ],
   "id": "b28902cbfc0b0967",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. í•„í„°ë§í•  ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ì •ì˜\n",
    "words = \"ì„íƒ‘,ì…ìƒ,ì¢Œìƒ,ì¹ ì„±ë„,ì„ë“±,ê·¹ë½ì „,ê·¹ë½ë³´ì „,ì „íƒ‘,ë¬´ëŸ‰ìˆ˜ì „,ë¶ˆêµ­ì‚¬,í•´ì¸ì‚¬,ì†¡ê´‘ì‚¬,í†µë„ì‚¬,ë°±ë‹´ì‚¬,ë™í™”ì‚¬,ë²½í™”,ëŒ€ì›…ì „,ìŠ¹íƒ‘,ë²•ì£¼ì‚¬,ì—¬ë˜,êµ­ì‚¬íƒ‘,ì‚¬íƒ‘,ê´˜ë¶ˆíƒ±,íƒ±í™”,ë™ì¢…,ë°˜ê°€ìƒ,ë¯¸ë¥µë¶ˆ,ë³´ì‚´,ë‚˜í•œìƒ,ê´˜ë¶ˆ\".split(\",\")\n",
    "\n",
    "# 2. ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ ìƒì„± (ë‹¨ì–´ë“¤ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ëœ ê²½ìš°)\n",
    "pattern = \"|\".join(words)\n",
    "\n",
    "# 3. ccbaMnm1 ì»¬ëŸ¼ì—ì„œ í•´ë‹¹ ë‹¨ì–´ê°€ í¬í•¨ëœ ë°ì´í„° í•„í„°ë§\n",
    "# na=Falseë¥¼ ì„¤ì •í•˜ì—¬ NaN ê°’ì´ ìˆëŠ” ê²½ìš° ì—ëŸ¬ ë°©ì§€\n",
    "filtered_df = df[df['ccbaMnm1'].str.contains(pattern, na=False)].copy()\n",
    "\n",
    "result_df = filtered_df.groupby(['ccbaCtcdNm', 'ccsiName', 'ccbaAdmin'])['ccbaMnm1'].agg(\n",
    "    count='count',\n",
    "    all_name=lambda x: \"|\".join(x.astype(str))\n",
    ").reset_index()\n",
    "result_df.to_excel('ì§€ì—­_êµ­ê°€ìœ ì‚°___.xlsx')\n",
    "\n",
    "#\n",
    "# df_area = df.groupby(['ccbaCtcdNm', 'ccsiName', 'ccbaAdmin']).agg(\n",
    "#     count_ccbaMnm1=('ccbaMnm1', 'count'),  # ê°œìˆ˜ ê²€ì‚¬\n",
    "#     all_name=('ccbaMnm1', lambda x: \"|\".join(x.astype(str)))  # \"|\" êµ¬ë¶„ìë¡œ í•©ì¹˜ê¸°\n",
    "# ).reset_index()\n",
    "# df_area.to_excel('ì§€ì—­_êµ­ê°€ìœ ì‚°___.xlsx')"
   ],
   "id": "408684049edbba11",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
